{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d9a3f8",
   "metadata": {},
   "source": [
    "Concatenating ICMS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018cf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found runs (in order):\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_2_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_3_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_4_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_5_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_7_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_9_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_10_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_12_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_13_g0\n",
      "  - C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_14_g0\n",
      "\n",
      "Saving AP (binary)...\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=4 - samples_per_chunk=150,000 - chunk_memory=109.86 MiB - total_memory=439.45 MiB - chunk_duration=5.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d583579c97344034842847e6b5a60dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 4 processes):   0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving NiDq (binary)...\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=4 - samples_per_chunk=52,966 - chunk_memory=931.04 KiB - total_memory=3.64 MiB - chunk_duration=5.00s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509f1f87060044d586740848959a3483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 4 processes):   0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY ===\n",
      "AP  -> C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_All_Concat_g0\\ap_binary\n",
      "   fs=30000.0 Hz | nch=384 | duration=1278.11 s | common_channels=384\n",
      "NiDq-> C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_All_Concat_g0\\nidq_binary\n",
      "   fs=10593.220339 Hz | nch=9 | duration=1278.11 s | common_channels=9\n",
      "\n",
      "Re-open later with:\n",
      "  rec_ap = spikeinterface.extractors.read_binary_folder(r'C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_All_Concat_g0\\ap_binary')\n",
      "  nidq   = spikeinterface.extractors.read_binary_folder(r'C:\\storage\\Reza\\rat data\\08-08-2025\\ICMSstim_icmsstim_All_Concat_g0\\nidq_binary')\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "BASE_DIR     = Path(r\"C:/storage/Reza/rat data/08-08-2025\")  # the date folder\n",
    "SESSION_GLOB = \"ICMSstim_icmsstim_*_g0\"                      # pattern for runs\n",
    "TARGET_DIR   = Path(r\"C:/storage/Reza/rat data/08-08-2025/ICMSstim_icmsstim_All_Concat_g0\")\n",
    "\n",
    "# IO speedups for saving; adjust as needed\n",
    "JOB_KW = dict(n_jobs=4, progress_bar=True, chunk_duration=\"5s\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def list_runs(base_dir: Path, pattern: str) -> list[Path]:\n",
    "    \"\"\"Find and numerically sort run folders like ..._2_g0, ..._3_g0, ..._14_g0. Skip the All_Concat target.\"\"\"\n",
    "    runs = []\n",
    "    for d in base_dir.glob(pattern):\n",
    "        if \"All_Concat_g0\" in d.name:\n",
    "            continue\n",
    "        m = re.search(r\"_(\\d+)_g\\d+$\", d.name)  # capture the run index before _g#\n",
    "        idx = int(m.group(1)) if m else -1\n",
    "        runs.append((idx, d))\n",
    "    runs.sort(key=lambda x: x[0])\n",
    "    return [d for _, d in runs]\n",
    "\n",
    "\n",
    "def read_spikeglx_run(run_dir: Path):\n",
    "    \"\"\"Read imec0.ap and nidq streams from a single SpikeGLX run directory.\"\"\"\n",
    "    stem = run_dir.name  # e.g., ICMSstim_icmsstim_2_g0\n",
    "    imec_dir = run_dir / f\"{stem}_imec0\"\n",
    "    if not imec_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing imec folder: {imec_dir}\")\n",
    "\n",
    "    rec_ap = se.read_spikeglx(str(imec_dir), stream_id=\"imec0.ap\")\n",
    "    nidq   = se.read_spikeglx(str(run_dir),  stream_id=\"nidq\")\n",
    "    return rec_ap, nidq\n",
    "\n",
    "\n",
    "def check_fs_compatible(recordings, tol=1e-9, label=\"\"):\n",
    "    fs0 = recordings[0].sampling_frequency\n",
    "    for i, r in enumerate(recordings[1:], start=1):\n",
    "        if abs(r.sampling_frequency - fs0) > tol:\n",
    "            raise ValueError(f\"[{label}] Sampling rate mismatch: {fs0} vs {r.sampling_frequency} (run idx {i})\")\n",
    "\n",
    "\n",
    "def subset_channels(rec, channel_ids):\n",
    "    \"\"\"\n",
    "    Version-agnostic channel selection on a Recording:\n",
    "      1) recording.select_channels(...)   (newer SI)\n",
    "      2) recording.channel_slice(...)     (older SI)\n",
    "      3) ChannelSliceRecording(...)       (lowest-level fallback)\n",
    "    \"\"\"\n",
    "    if hasattr(rec, \"select_channels\"):\n",
    "        return rec.select_channels(channel_ids=channel_ids)\n",
    "    if hasattr(rec, \"channel_slice\"):\n",
    "        return rec.channel_slice(channel_ids=channel_ids)\n",
    "    try:\n",
    "        from spikeinterface import ChannelSliceRecording  # fallback (older core class)\n",
    "        return ChannelSliceRecording(rec, channel_ids=channel_ids)\n",
    "    except Exception as e:\n",
    "        raise AttributeError(\n",
    "            \"Could not subset channels with select_channels/channel_slice/ChannelSliceRecording. \"\n",
    "            \"Please update SpikeInterface.\"\n",
    "        ) from e\n",
    "\n",
    "\n",
    "def align_to_common_channels(recordings, label=\"\"):\n",
    "    \"\"\"Keep the intersection across runs (ordered as in the first run), then subset every run to that list.\"\"\"\n",
    "    check_fs_compatible(recordings, label=label)\n",
    "\n",
    "    ref_ids = np.asarray(recordings[0].get_channel_ids())\n",
    "    common = set(ref_ids.tolist())\n",
    "    for r in recordings[1:]:\n",
    "        common &= set(np.asarray(r.get_channel_ids()).tolist())\n",
    "\n",
    "    if not common:\n",
    "        raise ValueError(f\"[{label}] No common channels across runs. Check per-run channel maps.\")\n",
    "\n",
    "    common_ids = [cid for cid in ref_ids if cid in common]\n",
    "    if len(common_ids) < len(ref_ids):\n",
    "        print(f\"[warn/{label}] Reducing to {len(common_ids)} common channels (from {len(ref_ids)}).\")\n",
    "\n",
    "    aligned = [subset_channels(r, common_ids) for r in recordings]\n",
    "    return aligned, common_ids\n",
    "\n",
    "\n",
    "def concatenate_with_alignment(recordings, label=\"\"):\n",
    "    aligned, common_ids = align_to_common_channels(recordings, label=label)\n",
    "    rec_concat = si.concatenate_recordings(aligned)  # single long segment (time-concatenated)\n",
    "    return rec_concat, common_ids\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    runs = list_runs(BASE_DIR, SESSION_GLOB)\n",
    "    if not runs:\n",
    "        raise RuntimeError(f\"No runs matching '{SESSION_GLOB}' in {BASE_DIR}\")\n",
    "\n",
    "    print(\"Found runs (in order):\")\n",
    "    for d in runs:\n",
    "        print(\"  -\", d)\n",
    "\n",
    "    # Read all runs\n",
    "    ap_list, nidq_list = [], []\n",
    "    for rd in runs:\n",
    "        rec_ap, nidq = read_spikeglx_run(rd)\n",
    "        ap_list.append(rec_ap)\n",
    "        nidq_list.append(nidq)\n",
    "\n",
    "    # Align channels and concatenate in time\n",
    "    rec_ap_concat, ap_common   = concatenate_with_alignment(ap_list,  label=\"AP\")\n",
    "    nidq_concat, nidq_common   = concatenate_with_alignment(nidq_list, label=\"NiDq\")\n",
    "\n",
    "    # # Save to Zarr via the instance method .save(...)\n",
    "    # TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    # ap_out   = TARGET_DIR / \"ap_zarr\"\n",
    "    # nidq_out = TARGET_DIR / \"nidq_zarr\"\n",
    "\n",
    "    # print(\"\\nSaving AP (zarr)...\")\n",
    "    # rec_ap_saved = rec_ap_concat.save(folder=str(ap_out), format=\"zarr\", **JOB_KW)\n",
    "\n",
    "    # print(\"Saving NiDq (zarr)...\")\n",
    "    # nidq_saved   = nidq_concat.save(folder=str(nidq_out), format=\"zarr\", **JOB_KW)\n",
    "\n",
    "    # Save to binary via the instance method .save(...)\n",
    "    TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    ap_out   = TARGET_DIR / \"ap_binary\"\n",
    "    nidq_out = TARGET_DIR / \"nidq_binary\"\n",
    "\n",
    "    print(\"\\nSaving AP (binary)...\")\n",
    "    # pick a dtype; int16 keeps files small and matches SpikeGLX raw\n",
    "    rec_ap_saved = rec_ap_concat.save(folder=str(ap_out), format=\"binary\",\n",
    "                                    dtype=\"int16\", **JOB_KW)\n",
    "\n",
    "    print(\"Saving NiDq (binary)...\")\n",
    "    nidq_saved   = nidq_concat.save(folder=str(nidq_out), format=\"binary\",\n",
    "                                    dtype=\"int16\", **JOB_KW)\n",
    "\n",
    "    # Info\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    print(f\"AP  -> {ap_out}\")\n",
    "    print(f\"   fs={rec_ap_saved.sampling_frequency} Hz | nch={rec_ap_saved.get_num_channels()} | \"\n",
    "          f\"duration={rec_ap_saved.get_total_duration():.2f} s | common_channels={len(ap_common)}\")\n",
    "    print(f\"NiDq-> {nidq_out}\")\n",
    "    print(f\"   fs={nidq_saved.sampling_frequency} Hz | nch={nidq_saved.get_num_channels()} | \"\n",
    "          f\"duration={nidq_saved.get_total_duration():.2f} s | common_channels={len(nidq_common)}\")\n",
    "\n",
    "    # print(\"\\nRe-open later with:\")\n",
    "    # print(f\"  rec_ap = si.read_zarr(r'{ap_out}')\")\n",
    "    # print(f\"  nidq   = si.read_zarr(r'{nidq_out}')\")\n",
    "\n",
    "    print(\"\\nRe-open later with:\")\n",
    "    print(f\"  rec_ap = spikeinterface.extractors.read_binary_folder(r'{ap_out}')\")\n",
    "    print(f\"  nidq   = spikeinterface.extractors.read_binary_folder(r'{nidq_out}')\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da7fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
